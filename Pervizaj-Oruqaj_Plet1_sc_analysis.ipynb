{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "scv.set_figure_params()\n",
    "%config Completer.use_jedi = False\n",
    "import seaborn as sb\n",
    "import gc\n",
    "import scrublet as scr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-phrase",
   "metadata": {},
   "source": [
    "# Read Alignment with StarSolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-encounter",
   "metadata": {},
   "source": [
    "This scanpy code utilizes a .csv document as well as the output files of StarSolo.   \n",
    "We provide the aligned folders (STAR output) which are imported later during this script as downloadable .tar archives:   \n",
    "If the downloads do not function properly, please write to david.glaser@bio.uni-giessen.de or marek.bartkuhn@gen.bio.uni-giessen.de   \n",
    "\n",
    "S3 storage:\n",
    "https://s3.computational.bio.uni-giessen.de/swift/v1/plet1_paper_Pervizaj_2023/   \n",
    "\n",
    "A1_wpre_outSolo.out.tar   \n",
    "A2_wpre_outSolo.out.tar   \n",
    "A3_wpre_outSolo.out.tar   \n",
    "B1_wpre_outSolo.out.tar   \n",
    "B2_wpre_outSolo.out.tar   \n",
    "B3_wpre_outSolo.out.tar   \n",
    "C1_new_wpre_outSolo.out.tar   \n",
    "C1_wpre_outSolo.out.tar   \n",
    "C2_new_wpre_outSolo.out.tar   \n",
    "C2_wpre_outSolo.out.tar   \n",
    "C3_new_wpre_outSolo.out.tar   \n",
    "D1_wpre_outSolo.out.tar   \n",
    "D2_wpre_outSolo.out.tar   \n",
    "D3_wpre_outSolo.out.tar   \n",
    "E1_wpre_outSolo.out.tar   \n",
    "E2_wpre_outSolo.out.tar   \n",
    "E3_wpre_outSolo.out.tar   \n",
    "\n",
    "However, if you prefer aligning the data yourself, we used the following Star call (fastq files are available at GEO ):   \n",
    "\n",
    "STAR   \n",
    "--genomeDir /path/to/genome/index/   \n",
    "--readFilese /path/to/XXX_R2_001.fastq.gz /path/to/XXX_R1_001.fastq.gz    \n",
    "--soloType CB_UMI_Simple   \n",
    "--runThreadN 8     \n",
    "--soloCBwhitelist /path/to/10xBarcodes/3M-february-2018.txt   \n",
    "--readFilesCommand zcat   \n",
    "--outSAMtype BAM SortedByCoordinate   \n",
    "--soloFeatures Gene Velocyto   \n",
    "--clipAdapterType CellRanger4   \n",
    "--outFilterScoreMin 30   \n",
    "--soloCBmatchWLtype 1MM_multi_Nbase_pseudocounts   \n",
    "--soloUMIfiltering MultiGeneUMI_CR   \n",
    "--soloUMIdedup 1MM_CR   \n",
    "--soloBarcodeReadLength 28 --soloCBstart 1 --soloCBlen 16 --soloUMIstart17 --soloUMIlen 12 --soloCellFilter EmptyDrops_CR   \n",
    "--outFileNamePrefix /work/C1_new_wpre_out   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-fifth",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change to directory which contains \"scanpyInput.csv\" and Star output files (eg. A1_wpre_outSolo.out)\n",
    "\n",
    "expName = \"Infection_timecourse\" # Name given to the experimental setup\n",
    "os.chdir(\"/root/host_home/\") # This is the path to files in the docker container.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-forwarding",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"scanpyInput.csv\",sep=\",\")\n",
    "df = df.sort_values([\"timepoint\",\"replicate\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to automatically import Star output and transfer to anndata object\n",
    "\n",
    "def buildAnndataFromStarCurr(path):\n",
    "    \"\"\"Generate an anndata object from the STAR aligner output folder\"\"\"\n",
    "    path=path\n",
    "    print(path)\n",
    "    # Load Read Counts\n",
    "    X = sc.read_mtx(path+'Gene/raw/matrix.mtx')\n",
    "\n",
    "    # Transpose counts matrix to have Cells as rows and Genes as cols as expected by AnnData objects\n",
    "    X = X.X.transpose()\n",
    "\n",
    "    # Load the 3 matrices containing Spliced, Unspliced and Ambigous reads\n",
    "    mtxU = np.loadtxt(path+'Velocyto/raw/unspliced.mtx', skiprows=3, delimiter=' ')\n",
    "    mtxS = np.loadtxt(path+'Velocyto/raw/spliced.mtx', skiprows=3, delimiter=' ')\n",
    "    mtxA = np.loadtxt(path+'Velocyto/raw/ambiguous.mtx', skiprows=3, delimiter=' ')\n",
    "\n",
    "    # Extract sparse matrix shape informations from the third row\n",
    "    shapeU = np.loadtxt(path+'Velocyto/raw/unspliced.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "    shapeS = np.loadtxt(path+'Velocyto/raw/spliced.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "    shapeA = np.loadtxt(path+'Velocyto/raw/ambiguous.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "\n",
    "    # Read the sparse matrix with csr_matrix((data, (row_ind, col_ind)), shape=(M, N))\n",
    "    # Subract -1 to rows and cols index because csr_matrix expects a 0 based index\n",
    "    # Traspose counts matrix to have Cells as rows and Genes as cols as expected by AnnData objects\n",
    "\n",
    "    spliced = sparse.csr_matrix((mtxS[:,2], (mtxS[:,0]-1, mtxS[:,1]-1)), shape = shapeS).transpose()\n",
    "    unspliced = sparse.csr_matrix((mtxU[:,2], (mtxU[:,0]-1, mtxU[:,1]-1)), shape = shapeU).transpose()\n",
    "    ambiguous = sparse.csr_matrix((mtxA[:,2], (mtxA[:,0]-1, mtxA[:,1]-1)), shape = shapeA).transpose()\n",
    "\n",
    "    # Load Genes and Cells identifiers\n",
    "    obs = pd.read_csv(path+'Velocyto/raw/barcodes.tsv',\n",
    "                  header = None, index_col = 0)\n",
    "\n",
    "    # Remove index column name to make it compliant with the anndata format\n",
    "    obs.index.name = None\n",
    "\n",
    "    var = pd.read_csv(path+'Velocyto/raw/features.tsv', sep='\\t',\n",
    "                                    names = ('gene_ids', 'feature_types'), index_col = 1)\n",
    "  \n",
    "    # Build AnnData object to be used with ScanPy and ScVelo\n",
    "    adata = anndata.AnnData(X = X, obs = obs, var = var,\n",
    "                                                 layers = {'spliced': spliced, 'unspliced': unspliced, 'ambiguous': ambiguous})\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    # Subset Cells based on STAR filtering\n",
    "    selected_barcodes = pd.read_csv(path+'Gene/filtered/barcodes.tsv', header = None)\n",
    "    adata = adata[selected_barcodes[0]]\n",
    "\n",
    "    return adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-routine",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function call for buildAnndataFromStarCurr. First checks whether h5ad files already exist, then read it.\n",
    "## Otherwise, create h5ad from Star output.\n",
    "\n",
    "from os.path import exists\n",
    "alldata = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row['Sample'], row['StarSoloFolder'])\n",
    "    importFile = row['Sample'] + \"-3rawImport.h5ad\"\n",
    "    print(importFile)\n",
    "    starSoloFolder = row['StarSoloFolder']\n",
    "    file_exists = exists(importFile)\n",
    "    \n",
    "    if file_exists:\n",
    "        print(\"file \" + importFile + \" already there!\")\n",
    "        print(\"reading it ...\")\n",
    "        alldata[row['Sample']] = sc.read_h5ad(importFile)\n",
    "    else:\n",
    "        print(\"file \" + importFile + \" not there!\")\n",
    "        print(\"importing STARsolo data ...\")\n",
    "        alldata[row['Sample']] = buildAnndataFromStarCurr(starSoloFolder)\n",
    "        alldata[row['Sample']].write_h5ad(filename=importFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row['Sample'], row['timepoint'])        \n",
    "    alldata[row['Sample']].obs['sample']=row['Sample']\n",
    "    alldata[row['Sample']].obs['time']=str(row['timepoint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-sweden",
   "metadata": {},
   "source": [
    "# Doublet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scrublet parameters (DEFAULT)\n",
    "#scanpy.external.pp.scrublet(adata, adata_sim=None, batch_key=None, sim_doublet_ratio=2.0, expected_doublet_rate=0.05, \n",
    "#                            stdev_doublet_rate=0.02, synthetic_doublet_umi_subsampling=1.0, knn_dist_metric='euclidean', \n",
    "#                            normalize_variance=True, log_transform=False, mean_center=True, n_prin_comps=30, use_approx_neighbors=True, \n",
    "#                            get_doublet_neighbor_parents=False, n_neighbors=None, threshold=None, verbose=True, copy=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in alldata:\n",
    "    \n",
    "    alldata[i].var_names_make_unique()\n",
    "    scrub = scr.Scrublet(alldata[i].X)\n",
    "    alldata[i].obs['doublet_scores'],alldata[i].obs['predicted_doublets'] = scrub.scrub_doublets()\n",
    "    sum(alldata[i].obs['predicted_doublets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-education",
   "metadata": {},
   "source": [
    "# Concatenate samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-brief",
   "metadata": {},
   "source": [
    "If you do not have more than 120 GB of free RAM available, you need to concatenate the data in two steps. Otherwise Scanpy will crash.\n",
    "When enough RAM is available please continue at the indicated step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(alldata)\n",
    "len(alldata)\n",
    "keys_list = list(alldata)\n",
    "for i in range(1,9):\n",
    "        print(i)\n",
    "        if i==1:\n",
    "            part1 = alldata[keys_list[i-1]].concatenate(alldata[keys_list[i]])\n",
    "        else:\n",
    "            part1 = part1.concatenate(alldata[keys_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.write_h5ad(os.getcwd() + \"/part1_raw_concat.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "del part1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(alldata)\n",
    "len(alldata)\n",
    "keys_list = list(alldata)\n",
    "for i in range(10,len(alldata)):\n",
    "        print(i)\n",
    "        if i==10:\n",
    "            part2 = alldata[keys_list[i-1]].concatenate(alldata[keys_list[i]])\n",
    "        else:\n",
    "            part2 = part2.concatenate(alldata[keys_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2.write_h5ad(os.getcwd() + \"/part2_raw_concat.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = sc.read_h5ad(os.getcwd() + \"/part1_raw_concat.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data = part1.concatenate(part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save concatenate but raw data\n",
    "concatenate_data.write_h5ad(os.getcwd() + \"/concatenate_data_raw.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove alldata object (containing individual time point anndata samples) from memory.\n",
    "del part2\n",
    "del part1\n",
    "del alldata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-appointment",
   "metadata": {},
   "source": [
    "When enough RAM is available, you can use this concatenation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(alldata)\n",
    "len(alldata)\n",
    "keys_list = list(alldata)\n",
    "for i in range(1,len(alldata)):\n",
    "        print(i)\n",
    "        if i==1:\n",
    "            concatenate_data = alldata[keys_list[i-1]].concatenate(alldata[keys_list[i]])\n",
    "        else:\n",
    "            concatenate_data = concatenate_data.concatenate(alldata[keys_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save concatenate but raw data\n",
    "concatenate_data.write_h5ad(os.getcwd() + \"/concatenate_data_raw.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove alldata object (containing individual time point anndata samples) from memory.\n",
    "del alldata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-development",
   "metadata": {},
   "source": [
    "# Cell numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concatenate_data.obs['sample'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-donor",
   "metadata": {},
   "source": [
    "# QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitochondrial genes\n",
    "concatenate_data.var['mt'] = concatenate_data.var_names.str.startswith('mt-') \n",
    "# ribosomal genes\n",
    "concatenate_data.var['ribo'] = concatenate_data.var_names.str.startswith((\"Rps\",\"Rpl\"))\n",
    "# hemoglobin genes.\n",
    "concatenate_data.var['hb'] = concatenate_data.var_names.str.contains((\"^Hb[^(P)]\"))\n",
    "sc.pp.calculate_qc_metrics(concatenate_data, qc_vars=['mt','ribo','hb'], percent_top=None, log1p=False, inplace=True)\n",
    "concatenate_data.var['Ptprc'] = concatenate_data.var_names.str.contains('Ptprc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-durham",
   "metadata": {},
   "source": [
    "# Filtering  bad cells and genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells according to identified QC thresholds:\n",
    "print('Total number of cells: {:d}'.format(concatenate_data.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(concatenate_data, min_counts = 1500)\n",
    "print('Number of cells after min count filter: {:d}'.format(concatenate_data.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(concatenate_data, max_counts = 40000)\n",
    "print('Number of cells after max count filter: {:d}'.format(concatenate_data.n_obs))\n",
    "\n",
    "adata = concatenate_data[concatenate_data.obs['pct_counts_mt'] < 15]\n",
    "print('Number of cells after MT filter: {:d}'.format(concatenate_data.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(concatenate_data, min_genes = 2000)\n",
    "print('Number of cells after gene filter: {:d}'.format(concatenate_data.n_obs))\n",
    "\n",
    "\n",
    "\n",
    "#Filter genes:\n",
    "print('Total number of genes: {:d}'.format(concatenate_data.n_vars))\n",
    "\n",
    "# Min 20 cells - filters out 0 count genes\n",
    "sc.pp.filter_genes(concatenate_data, min_cells=20)\n",
    "print('Number of genes after cell filter: {:d}'.format(concatenate_data.n_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Latching concatenated and quality controlled data\n",
    "\n",
    "fileName = expName + \"_concatenated_QCed.h5ad\"\n",
    "\n",
    "concatenate_data.write_h5ad(os.getcwd() + \"/\" + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data = sc.read_h5ad(\"/root/host_home/Infection_timecourse_concatenated_QCed.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-winter",
   "metadata": {},
   "source": [
    "# Cell numbers after QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concatenate_data.obs['sample'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-confirmation",
   "metadata": {},
   "source": [
    "# Normalize, Cluster and Integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(concatenate_data, min_cells=20)\n",
    "concatenate_data.raw = concatenate_data\n",
    "# normalize to depth 10 000\n",
    "sc.pp.normalize_per_cell(concatenate_data, counts_per_cell_after=1e4)\n",
    "\n",
    "concatenate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmize\n",
    "sc.pp.log1p(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(concatenate_data, flavor='cell_ranger', n_top_genes=4000)\n",
    "print('\\n','Number of highly variable genes: {:d}'.format(np.sum(concatenate_data.var['highly_variable'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-vector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integration using Harmony and subsequent embedding and UMAP calculation\n",
    "\n",
    "integrationMethod = \"harmony\"\n",
    "import scanpy.external as sce\n",
    "# Calculate the visualizations\n",
    "sc.pp.pca(concatenate_data, n_comps=50, use_highly_variable=True, svd_solver='arpack')\n",
    "sce.pp.harmony_integrate(concatenate_data, key='sample')\n",
    "sc.pp.neighbors(concatenate_data,use_rep = 'X_pca_harmony')\n",
    "sc.tl.umap(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save integrated h5ad file\n",
    "\n",
    "fileName = expName + \"_integrated.h5ad\"\n",
    "\n",
    "concatenate_data.write_h5ad(os.getcwd() + \"/\" + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate leiden clustering with various resolutions\n",
    "\n",
    "sc.tl.leiden(concatenate_data, key_added = \"leiden_1.0\") # default resolution in 1.0\n",
    "sc.tl.leiden(concatenate_data, resolution = 1.4, key_added = \"leiden_1.4\")\n",
    "sc.tl.leiden(concatenate_data, resolution = 0.6, key_added = \"leiden_0.6\")\n",
    "sc.tl.leiden(concatenate_data, resolution = 0.4, key_added = \"leiden_0.4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot size parameters.\n",
    "# please change according to your needs.\n",
    "# This will also change the plot size of the plots you save!\n",
    "\n",
    "plt.rcParams['figure.figsize']=(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concatenate_data, color=['leiden_1.0','leiden_0.6'], size=8)\n",
    "sc.pl.umap(concatenate_data, color=['leiden_0.4','leiden_1.4'], size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concatenate_data, color=['sample','time'], size=8)\n",
    "sc.pl.umap(concatenate_data, color=['n_counts','leiden_1.0'], size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concatenate_data, color=['doublet_score'], size=8) \n",
    "sc.pl.umap(concatenate_data, color=['predicted_doublet_str'], size=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concatenate_data, color=['predicted_doublet_str'], size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-province",
   "metadata": {},
   "source": [
    "# Marker Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openpyxl import Workbook\n",
    "BaseDirectory = os.getcwd()\n",
    "\n",
    "mycluster = \"Manual_annotation\"\n",
    "\n",
    "# sc.pl.violin(concatenate_data, ['Acta2', 'Sftpb','Sftpc'], groupby=mycluster)\n",
    "# sc.pl.violin(concatenate_data, ['Apoe', 'C1qa','Fn1'], groupby=mycluster)\n",
    "# sc.pl.violin(concatenate_data, ['S100a8', 'Csf3r','Lrg1'], groupby=mycluster)\n",
    "# sc.pl.violin(concatenate_data, ['Cpa3', 'Gata2','Ms4a2'], groupby=mycluster)\n",
    "\n",
    "# sc.pl.violin(concatenate_data, ['Cd247', 'Cd96','Nkg7'], groupby=mycluster)\n",
    "# sc.pl.violin(concatenate_data, ['Prf1', 'Cd3d','Cd28'], groupby=mycluster)\n",
    "\n",
    "# sc.pl.violin(concatenate_data, ['Cd79a', 'Bank1','Tcf4'], groupby=mycluster)\n",
    "# sc.pl.violin(concatenate_data, ['Tspan13', 'Pacsin1','Nucb2'], groupby=mycluster)\n",
    "\n",
    "\n",
    "#markers = ['Acta2', 'Sftpb','Sftpc','Apoe', 'C1qa','Fn1','S100a8', \n",
    "#           'Csf3r','Lrg1','Cpa3', 'Gata2','Ms4a2','Cd247', 'Cd96','Nkg7','Prf1', \n",
    "#           'Cd3d','Cd28','Cd79a', 'Bank1','Tcf4','Tspan13', 'Pacsin1','Nucb2']\n",
    "#sc.pl.dotplot(concatenate_data,markers, groupby=mycluster,dendrogram=True)\n",
    "\n",
    "sc.tl.rank_genes_groups(concatenate_data,groupby=mycluster)\n",
    "print(pd.DataFrame(concatenate_data.uns['rank_genes_groups']['names']).head(10))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "sampleName = expName\n",
    "method = 't-test' #t-test, wilcoxon, or logreg\n",
    "cluster_method = mycluster\n",
    "n_genes=1000 #set to adata.var.shape[0] to include all highly variable genes\n",
    "\n",
    "sc.tl.rank_genes_groups(concatenate_data, cluster_method, use_raw=True, pts=True, n_genes=n_genes, method=method)\n",
    "#sc.pl.rank_genes_groups(a, groupby=cluster_method, use_raw=False, n_genes=25, sharey=False, save='_' + str(sampleName) + '_' + method + '_' +  cluster_method + '_clusters')\n",
    "pd.DataFrame(concatenate_data.uns['rank_genes_groups']['names']).head(n_genes) #ALTER NUMBER TO SPECIFIC NUMBER OF GENES TO LIST\n",
    "table = pd.DataFrame(concatenate_data.uns['rank_genes_groups']['names']).head(n_genes) #ALTER NUMBER TO SPECIFIC NUMBER OF GENES TO LIST\n",
    "##### table.to_excel(os.path.join(BaseDirectory, sampleName + '_' + method + '_' + cluster_method + '_cluster_table_' + str(n_genes) + 'genes.xlsx'), engine='openpyxl')\n",
    "#make table with p-values included\n",
    "result = concatenate_data.uns['rank_genes_groups']\n",
    "groups = result['names'].dtype.names\n",
    "if method != 'logreg':\n",
    "    pval_table = pd.DataFrame(\n",
    "            {group + '_' + key[:1]: result[key][group]\n",
    "            for group in groups for key in ['names', 'pvals_adj','logfoldchanges']}).head(n_genes)\n",
    " ####   pval_table.to_excel(os.path.join(BaseDirectory, sampleName + '_' + method + '_pval_table_' + cluster_method + '_clusters_' + str(n_genes) + 'genes_filtered_corrected.xlsx'), engine='openpyxl')\n",
    "elif method=='logreg':\n",
    "        pval_table = pd.DataFrame(\n",
    "            {group + '_' + key[:2]: result[key][group]\n",
    "            for group in groups for key in ['names', 'scores']}).head(n_genes)\n",
    " ####       pval_table.to_excel(os.path.join(BaseDirectory, sampleName + '_' + method + '_coefs_' + cluster_method + '_clusters_' + str(n_genes) + 'genes_filtered_corrected.xlsx'), engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(concatenate_data.uns['rank_genes_groups']['names']).head(n_genes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330c09d-dee2-44d2-bcc2-964043161a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad5786-b4ea-4718-8520-bd743d9ed5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3d00a-1880-4d9a-8eb5-443117be4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dotplot of marker genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = ['Itgax', 'Siglecf', 'Ear2', 'Apoe', 'Ccr5', 'Mertk', 'Fcgr1', 'Itgam', 'Cx3cr1', 'Ccr2' ,'Ly6c2' ,'Mcm3', 'Mcm4', 'Mcm5', 'Mcm6', 'Mki67', 'H2-Ab1', 'H2-Eb1', 'Ccr7', 'Cd3e', 'Cd8a', 'Cd3d', 'Gzmb', 'Gzma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(concatenate_data, marker_genes, groupby=\"Manual_annotation\",dendrogram=True, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-newark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "premium-exemption",
   "metadata": {},
   "source": [
    "## ANNOTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 'leiden_1.0' # set the clustering which shall be annotated!\n",
    "concatenate_data.obs['leiden_anno'] = concatenate_data.obs[mycluster]\n",
    "concatenate_data.obs\n",
    "res = pd.DataFrame(columns=concatenate_data.var_names, index=concatenate_data.obs['leiden_anno'].cat.categories)                                                                                                 \n",
    "\n",
    "for clust in concatenate_data.obs.leiden_anno.cat.categories: \n",
    "    res.loc[clust] = concatenate_data[concatenate_data.obs['leiden_anno'].isin([clust]),:].X.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This .csv file is the input for the R script below\n",
    "\n",
    "res.transpose().to_csv(\"Infection_timecourse_mean_gene_expression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic celltype annotation using scMCA in R\n",
    "\n",
    "## ## ## ## R CODE\n",
    "## ##\n",
    "library(scMCA)\n",
    "library(openxlsx)\n",
    "\n",
    "read_counts <- read.table(\"/path/to/mean_reads.csv\", sep=\",\" )\n",
    "rownames(read_counts) <- read_counts[,1]\n",
    "read_counts <- (read_counts[,-1])\n",
    "read_counts <- read_counts[-1,]\n",
    "\n",
    "mca_result_read_counts <- scMCA(scdata = read_counts, numbers_plot = 3)\n",
    "\n",
    "out_frame <- data.frame(cluster=gsub(\"X\",\"\",names(mca_result_read_counts[[3]])),type=mca_result_read_counts[[3]])\n",
    "write.csv(out_frame, file=\"/out/file/path/annotation.csv\",row.names = F) # PLEASE CHANGE PATH ACCORDINGLY!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/out/file/path/annotation.csv\",sep=\",\") # PLEASE CHANGE PATH ACCORDINGLY!\n",
    "print(df)\n",
    "cellTypes = df.to_dict()['type']\n",
    "cellTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(concatenate_data.obs['leiden_anno'])\n",
    "leiden = (concatenate_data.obs['leiden_anno'].to_numpy(dtype=None))\n",
    "leiden + \"_\" + [cellTypes[x] for x in leiden.astype(int)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcacluster = mycluster+'_MCA'\n",
    "concatenate_data.obs[mcacluster] = leiden + \"_\" + [cellTypes[x] for x in leiden.astype(int)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-velvet",
   "metadata": {},
   "source": [
    "# Manual annotation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4']\n",
    "\n",
    "\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='0', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='2', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='3', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='5', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='6', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='8', value='1') \n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='9', value='1') \n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='10', value='1') \n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='11', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='15', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='16', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='17', value='1')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='12', value='2')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='13', value='3')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='18', value='X')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='4', value='5')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='20', value='5')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='7', value='6')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='14', value='7')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='19', value='8')\n",
    "concatenate_data.obs['leiden_1.4_new'] = concatenate_data.obs['leiden_1.4_new'].replace(to_replace='X', value='4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder categories\n",
    "concatenate_data.obs['leiden_1.4_new'].cat.reorder_categories(['1', '2', '3', '4', '5', '6', '7', '8'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['leiden_1.4_new']\n",
    "\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='1', value='TR-AM')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='2', value='Cycling_TR-AM_1')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='3', value='Cycling_TR-AM_2')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='4', value='Cmpk2-high_TR_AM')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='5', value='BMDM1')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='6', value='BMDM2')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='7', value='DC')\n",
    "concatenate_data.obs['Manual_annotation'] = concatenate_data.obs['Manual_annotation'].replace(to_replace='8', value='T_Cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(8,8)\n",
    "sc.set_figure_params(dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set color palette\n",
    "mpl = [\"steelblue\",\"red\",\"purple\",\"pink\",\"darkorange\",\"green\",\"sienna\",\"grey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(concatenate_data, color=['Manual_annotation'], palette=mpl,frameon=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save annotated h5ad file\n",
    "\n",
    "fileName = expName + \"_annotated.h5ad\"\n",
    "\n",
    "concatenate_data.write_h5ad(os.getcwd() + \"/\" + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-thirty",
   "metadata": {},
   "source": [
    "# Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0 = concatenate_data[concatenate_data.obs[\"time\"] == \"d_00\"]\n",
    "sub_7 = concatenate_data[concatenate_data.obs[\"time\"] == \"d_07\"]\n",
    "sub_14 = concatenate_data[concatenate_data.obs[\"time\"] == \"d_14\"]\n",
    "sub_21 = concatenate_data[concatenate_data.obs[\"time\"] == \"d_21\"]\n",
    "sub_35 = concatenate_data[concatenate_data.obs[\"time\"] == \"d_35\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(sub_35, keys = ['Plet1'], groupby= \"Manual_annotation\", use_raw=False, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-advice",
   "metadata": {},
   "source": [
    "# Trackplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trackplot\n",
    "mg = pd.read_csv(\"tracklist_genes.csv\",sep=\",\")\n",
    "mg['genes'].values.tolist()\n",
    "sc.pl.tracksplot(concatenate_data, var_names=mg['genes'].values.tolist(),groupby=\"Manual_annotation\",save=\"trackplot_version1.png\",dendrogram=False,raw=False,palette=mpl)\n",
    "sc.pl.tracksplot(concatenate_data, var_names=mg['genes'].values.tolist(),groupby=\"Manual_annotation\",save=\"trackplot_version2.png\",dendrogram=True,raw=False,palette=mpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-hollywood",
   "metadata": {},
   "source": [
    "## VELOCITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data = sc.read_h5ad(\"/root/host_home/Infection_timecourse_leiden_clustered_mareks_docker.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in concatenate_data.obs['time'].unique():\n",
    "    asub = concatenate_data[concatenate_data.obs['time']==str(i)].copy()\n",
    "    asub.obs['clusters'] = asub.obs['Manual_annotation']\n",
    "    asub = asub[-asub.obs['Manual_annotation'].isin(['7','8'])]\n",
    "    print(asub)\n",
    "    print('Timepoint:' + i)\n",
    "    display(Markdown('### time point: {}'.format(i)))\n",
    "    scv.pl.proportions(asub)\n",
    "    scv.pp.filter_genes(asub, min_shared_counts=100)\n",
    "    scv.pp.normalize_per_cell(asub)\n",
    "    scv.pp.filter_genes_dispersion(asub, n_top_genes=500)\n",
    "    #scv.pp.log1p(a)\n",
    "    scv.pp.filter_and_normalize(asub, min_shared_counts=20, n_top_genes=500)\n",
    "    scv.pp.moments(asub, n_pcs=30, n_neighbors=30)\n",
    "    scv.tl.velocity(asub)\n",
    "    scv.tl.velocity_graph(asub)\n",
    "    outfilename = \"velocity_timepoint_\" + i +\"_colored.png\"\n",
    "    scv.pl.velocity_embedding_stream(asub, basis='umap',save=outfilename,palette=mpl)\n",
    "\n",
    "\n",
    "    mycluster=\"Manual_annotation\"\n",
    "    scv.tl.rank_velocity_genes(asub, groupby=mycluster, min_corr=.3)\n",
    "    df = scv.DataFrame(asub.uns['rank_velocity_genes']['names'])\n",
    "\n",
    "    scv.tl.velocity_pseudotime(asub)\n",
    "    scv.pl.scatter(asub, color='velocity_pseudotime', cmap='gnuplot')\n",
    "\n",
    "\n",
    "    # this is needed due to a current bug - bugfix is coming soon.\n",
    "    asub.uns['neighbors']['distances'] = asub.obsp['distances']\n",
    "    asub.uns['neighbors']['connectivities'] = asub.obsp['connectivities']\n",
    "\n",
    "    scv.tl.paga(asub, groups=mycluster)\n",
    "    df = scv.get_df(asub, 'paga/transitions_confidence', precision=2).T\n",
    "    df.style.background_gradient(cmap='Blues').format('{:.2g}')\n",
    "\n",
    "    outfilename = \"paga_timepoint_\" + i +\"_colored.png\"\n",
    "\n",
    "    scv.pl.paga(asub, basis='umap', size=50, alpha=.1,min_edge_width=2, node_size_scale=1.5,save=outfilename,palette=mpl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
